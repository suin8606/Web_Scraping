# -*- coding: utf-8 -*-
"""Web scraping Soccer Matches.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xU61W8ZZk-B7I_p-I3ZhzW-zejaVxhr4
"""

import requests

standings_url = "https://fbref.com/en/comps/9/Premier-League-Stats"

data=requests.get(standings_url) #downloading html pages

from bs4 import BeautifulSoup

soup=BeautifulSoup(data.text,'html.parser')

soup.find('table.stats_table')

standings_table=soup.select('table.stats_table')[0] #selecting table consisting the name

links=standings_table.find_all('a') #fidning all of 'a' tags

links=[x.get("href") for x in links]

links=[x for x in links if "/squads/" in x]

team_urls=[f"https://fbref.com{x}" for x in links]

team_urls

team_url=team_urls[2]; team_url #picking a specific team

data=requests.get(team_url)

import pandas as pd

matches=pd.read_html(data.text, match='Scores & Fixtures') #extracing match information for Liverpool

soup=BeautifulSoup(data.text)

links=soup.find_all('a')

links=[x.get('href')for x in links]

links=[x for x in links if x and 'all_comps/shooting/' in x] #extracking team stats for Liverpool

links

data=requests.get(f'https://fbref.com{links[0]}')

shooting=pd.read_html(data.text, match='Shooting')[0]

shooting.head()

#deleting multindex
shooting.columns=shooting.columns.droplevel()

shooting.head()

matches[0].head()

# merge on date & time
team_data=matches[0].merge(shooting[['Date','Sh','SoT','Dist','FK','PK','PKatt']], on='Date')

team_data.head()

team_data.columns

shooting.shape

matches[0].shape

team_data.shape

years=list(range(2023,2020, -1))

years

all_matches=[]

standing_url="https://fbref.com/en/comps/9/Premier-League-Stats"

import pandas as pd

import time
for year in years:
    data = requests.get(standings_url)
    soup = BeautifulSoup(data.text)
    standings_table = soup.select('table.stats_table')[0]

    links = [l.get("href") for l in standings_table.find_all('a')]
    links = [l for l in links if '/squads/' in l]
    team_urls = [f"https://fbref.com{l}" for l in links]

    previous_season = soup.select("a.prev")[0].get("href")
    standings_url = f"https://fbref.com{previous_season}"

    for team_url in team_urls:
        team_name = team_url.split("/")[-1].replace("-Stats", "").replace("-", " ")
        data = requests.get(team_url)
        matches = pd.read_html(data.text, match="Scores & Fixtures")[0]
        soup = BeautifulSoup(data.text)
        links = [l.get("href") for l in soup.find_all('a')]
        links = [l for l in links if l and 'all_comps/shooting/' in l]
        data = requests.get(f"https://fbref.com{links[0]}")
        shooting = pd.read_html(data.text, match="Shooting")[0]
        shooting.columns = shooting.columns.droplevel()
        try:
            team_data = matches.merge(shooting[['Date','Sh','SoT','Dist','FK','PK','PKatt']], on="Date")
        except ValueError:
            continue
        team_data = team_data[team_data["Comp"] == "Premier League"]

        team_data["Season"] = year
        team_data["Team"] = team_name
        all_matches.append(team_data)
        time.sleep(1)

match_df=pd.concat(all_matches)

match_df.head()

match_df.columns=[c.lower() for c in match_df.columns]

match_df.to_csv('match_df.csv')